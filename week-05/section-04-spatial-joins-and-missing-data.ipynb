{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 04: Spatial Joins and Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "from matplotlib.colors import ListedColormap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import box\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "data_path = os.path.join(\"data/\")\n",
    "\n",
    "country_bound_us = gpd.read_file(os.path.join(data_path, \"usa\", \n",
    "                                              \"usa-boundary-dissolved.shp\"))\n",
    "                                 \n",
    "state_bound_us = gpd.read_file(os.path.join(data_path, \"usa\", \n",
    "                                            \"usa-states-census-2014.shp\"))\n",
    "                               \n",
    "pop_places = gpd.read_file(os.path.join(data_path, \"global\", \n",
    "                                        \"ne_110m_populated_places_simple\", \n",
    "                                        \"ne_110m_populated_places_simple.shp\"))\n",
    "                                        \n",
    "ne_roads = gpd.read_file(os.path.join(data_path, \"global\", \n",
    "                                      \"ne_10m_roads\", \"ne_10m_roads.shp\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next dissolve the state data by region like you did in the previous lesson.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify the country boundary just a little bit to make this run faster\n",
    "country_bound_us_simp = country_bound_us.simplify(.2, preserve_topology=True)\n",
    "\n",
    "# Clip the roads to the US boundary - this will take about a minute to execute\n",
    "roads_cl = gpd.clip(ne_roads, country_bound_us_simp)\n",
    "roads_cl.crs = ne_roads.crs\n",
    "\n",
    "# Dissolve states by region\n",
    "regions_agg = state_bound_us.dissolve(by=\"region\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Joins in Python\n",
    "Just like you might do in ArcMap or QGIS you can perform spatial joins in Python too. A spatial join is when you append the attributes of one layer to another based upon its spatial relationship.\n",
    "\n",
    "So - for example if you have a roads layer for the United States, and you want to apply the “region” attribute to every road that is spatially in a particular region, you would use a spatial join. To apply a join you can use the ```geopandas.sjoin()``` function as following:\n",
    "\n",
    "```.sjoin(layer-to-add-region-to, region-polygon-layer)```\n",
    "\n",
    "Sjoin Arguments:\n",
    "The ```op``` argument specifies the type of join that will be applied\n",
    "\n",
    "- ```intersects```: Returns True if the boundary and interior of the object intersect in any way with those of the other.\n",
    "- ```within```: Returns True if the object’s boundary and interior intersect only with the interior of the other (not its boundary or exterior).\n",
    "- ```contains```: Returns True if the object’s interior contains the boundary and interior of the other object and their boundaries do not touch at all.\n",
    "[You can read more about each type here.](https://shapely.readthedocs.io/en/stable/manual.html?highlight=binary%20predicates#binary-predicates)\n",
    "\n",
    "How allows the following options: (this is taken directly from the [geopandas code on github!](https://github.com/geopandas/geopandas/blob/main/geopandas/tools/sjoin.py#L18)\n",
    "\n",
    "‘left’: use keys from left_df; retain only left_df geometry column\n",
    "‘right’: use keys from right_df; retain only right_df geometry column\n",
    "‘inner’: use intersection of keys from both dfs; retain only left_df geometry column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Roads within region\n",
    "roads_region = gpd.sjoin(roads_cl, \n",
    "                         regions_agg, \n",
    "                         how=\"inner\", \n",
    "                         op='intersects')\n",
    "\n",
    "# Notice once you have joins the data - you have attributes \n",
    "# from the regions_object (i.e. the region) attached to each road feature\n",
    "roads_region[[\"featurecla\", \"index_right\", \"ALAND\"]].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproject and plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproject to Albers for plotting\n",
    "country_albers = country_bound_us.to_crs('epsg:5070')\n",
    "roads_albers = roads_region.to_crs('epsg:5070')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "country_albers.plot(alpha=1,\n",
    "                    facecolor=\"none\",\n",
    "                    edgecolor=\"black\",\n",
    "                    zorder=10,\n",
    "                    ax=ax)\n",
    "\n",
    "roads_albers.plot(column='index_right',\n",
    "                  ax=ax,\n",
    "                  legend=True)\n",
    "\n",
    "# Adjust legend location\n",
    "leg = ax.get_legend()\n",
    "leg.set_bbox_to_anchor((1.15,1))\n",
    "\n",
    "ax.set_axis_off()\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to customize your legend even further, you can once again use loops to do so.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, create a dictionary with the attributes of each legend item\n",
    "road_attrs = {'Midwest': ['black'],\n",
    "              'Northeast': ['grey'],\n",
    "              'Southeast': ['m'],\n",
    "              'Southwest': ['purple'],\n",
    "              'West': ['green']}\n",
    "\n",
    "# Plot the data\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "regions_agg.plot(edgecolor=\"black\",\n",
    "                 ax=ax)\n",
    "country_albers.plot(alpha=1,\n",
    "                    facecolor=\"none\",\n",
    "                    edgecolor=\"black\",\n",
    "                    zorder=10,\n",
    "                    ax=ax)\n",
    "\n",
    "for ctype, data in roads_albers.groupby('index_right'):\n",
    "    data.plot(color=road_attrs[ctype][0],\n",
    "              label=ctype,\n",
    "              ax=ax)\n",
    "    \n",
    "# This approach works to place the legend when you have defined labels\n",
    "plt.legend(bbox_to_anchor=(1.0, 1), loc=2)\n",
    "ax.set_axis_off()\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Line Segment Length\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn off scientific notation\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "\n",
    "# Calculate the total length of road \n",
    "road_albers_length = roads_albers[['index_right', 'length_km']]\n",
    "\n",
    "# Sum existing columns\n",
    "roads_albers.groupby('index_right').sum()\n",
    "\n",
    "roads_albers['rdlength'] = roads_albers.length\n",
    "sub = roads_albers[['rdlength', 'index_right']].groupby('index_right').sum()\n",
    "sub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Data\n",
    "This lesson covers how to rename and clean up attribute data using **geopandas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import roads shapefile\n",
    "sjer_roads_path = os.path.join(\"data/california/madera-county-roads/tl_2013_06039_roads.shp\")\n",
    "sjer_roads = gpd.read_file(sjer_roads_path)\n",
    "\n",
    "type(sjer_roads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore Data Values\n",
    "\n",
    "There are several ways to use ```pandas``` to explore your data and determine if you have any missing values.\n",
    "\n",
    "- To find the number of missing values per column in a DataFrame you can run ```dfname.is_null().sum()```\n",
    "- Look at the unique values for a specific column of a DataFrame ```dfname['column'].unique()```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sjer_roads.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this method there are no ```NaN``` or ```None``` type obejcts as values in the ```geodataframe```. Double check the unique values in the road type column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View data type \n",
    "print(type(sjer_roads['RTTYP']))\n",
    "\n",
    "# View unique attributes for each road in the data\n",
    "print(sjer_roads['RTTYP'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing Values\n",
    "- If the value you want to replace is a Nan or Nonetype you can use ```dfname.loc[dfname['column'].isnull(), 'column' = 'newvaluu'```\n",
    "\n",
    "- Or you can use the pandas ```.fillna()``` method and .fullna takes in the value that you want to replace.\n",
    "\n",
    "Hmmmm there’s a road type that’s given an empty ```string``` as a name. It would be helpful to fix this before doing more analyis or mapping with this dataset.\n",
    "\n",
    "There are several ways to deal with this issue. One is to use the ```.replace``` method to replace all instances of None in the attribute data with some new value. In this case, you will use - ‘Unknown’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map each value to a new value \n",
    "sjer_roads[\"RTTYP\"] = sjer_roads[\"RTTYP\"].fillna(\"Unknown\")\n",
    "print(sjer_roads['RTTYP'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively you can use the ```.isnull()``` function to select all attribute cells with a value equal to ```null``` and set those to ‘Unknown’.\n",
    "\n",
    "If the value you want to change is not ```NaN``` or a ```Nonetype``` then you will have to specify the origina value that you want to change, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sjer_roads.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing Values\n",
    "\n",
    "\n",
    "In some specific instances you will want to remove ```NaN``` values from your ```DataFrame```, to do this you can use the ```pandas .dropna``` function, note that this function will remove all rows from the dataframe that have a ```Nan`` value in any of the columns."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('traillop')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31733d31b68f2bf33a40ef3744aa6e6dabc719cffbfa95fe2fcbd4a0d9e78042"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
