{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [`IPYNB`](../content/part2/06_points.ipynb)\n",
    "\n",
    "> **NOTE**: some of this material has been ported and adapted from \"Lab 9\" in [Arribas-Bel (2016)](http://darribas.org/gds15/labs/Lab_09.html).\n",
    "\n",
    "This notebook covers a brief introduction on how to visualize and analyze point patterns. To demonstrate this, we will use a dataset of all the AirBnb listings in the city of Austin (check the Data section for more information about the dataset).\n",
    "\n",
    "Before anything, let us load up the libraries we will use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import mplleaflet as mpll"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first set the paths to the datasets we will be using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adjust this to point to the right file in your computer\n",
    "listings_link = 'data/listings.csv.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The core dataset we will use is `listings.csv`, which contains a lot of information about each individual location listed at AirBnb within Austin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lst = pd.read_csv(listings_link)\n",
    "lst.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that one record displays a very odd location and, for the sake of the illustration, we will remove it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "odd = lst.loc[lst.longitude>-80, ['longitude', 'latitude']]\n",
    "odd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lst = lst.drop(odd.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most straighforward way to get a first glimpse of the distribution of the data is to plot their latitude and longitude:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sns.jointplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"longitude\", y=\"latitude\", data=lst);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this does not neccesarily tell us much about the dataset or the distribution of locations within Austin. There are two main challenges in interpreting the plot: one, there is lack of context, which means the points are not identifiable over space (unless you are so familiar with lon/lat pairs that they have a clear meaning to you); and two, in the center of the plot, there are so many points that it is hard to tell any pattern other than a big blurb of blue.\n",
    "\n",
    "Let us first focus on the first problem, geographical context. The quickest and easiest way to provide context to this set of points is to overlay a general map. If we had an image with the map or a set of several data sources that we could aggregate to create a map, we could build it from scratch. But in the XXI Century, the easiest is to overlay our point dataset on top of a web map. In this case, we will use [Leaflet](http://leafletjs.com/), and we will convert our underlying `matplotlib` points with `mplleaflet`. The full dataset (+5k observations) is a bit too much for leaflet to plot it directly on screen, so we will obtain a random sample of 100 points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NOTE: `mpll.display` turned off to be able to compile the website,\n",
    "#       comment out the last line of this cell for rendering Leaflet map.\n",
    "rids = np.arange(lst.shape[0])\n",
    "np.random.shuffle(rids)\n",
    "f, ax = plt.subplots(1, figsize=(6, 6))\n",
    "lst.iloc[rids[:100], :].plot(kind='scatter', x='longitude', y='latitude', \\\n",
    "                      s=30, linewidth=0, ax=ax);\n",
    "mpll.display(fig=f,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This map allows us to get a much better sense of where the points are and what type of location they might be in. For example, now we can see that the big blue blurb has to do with the urbanized core of Austin.\n",
    "\n",
    "### `bokeh` alternative\n",
    "\n",
    "Leaflet is not the only technology to display data on maps, although it is probably the default option in many cases. When the data is larger than \"acceptable\", we need to resort to more technically sophisticated alternatives. One option is provided by `bokeh` and its `datashaded` submodule (see [here](https://anaconda.org/jbednar/nyc_taxi/notebook) for a very nice introduction to the library, from where this example has been adapted).\n",
    "\n",
    "Before we delve into `bokeh`, let us reproject our original data (lon/lat coordinates) into Web Mercator, as `bokeh` will expect them. To do that, we turn the coordinates into a `GeoSeries`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import Point\n",
    "xys_wb = gpd.GeoSeries(lst[['longitude', 'latitude']].apply(Point, axis=1), \\\n",
    "                      crs=\"+init=epsg:4326\")\n",
    "xys_wb = xys_wb.to_crs(epsg=3857)\n",
    "x_wb = xys_wb.apply(lambda i: i.x)\n",
    "y_wb = xys_wb.apply(lambda i: i.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to setup the plot in `bokeh`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from bokeh.plotting import figure, output_notebook, show\n",
    "from bokeh.tile_providers import get_provider,Vendors\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "minx, miny, maxx, maxy = xys_wb.total_bounds\n",
    "y_range = miny, maxy\n",
    "x_range = minx, maxx\n",
    "\n",
    "def base_plot(tools='pan,wheel_zoom,reset',plot_width=600, plot_height=400, **plot_args):\n",
    "    p = figure(tools=tools, plot_width=plot_width, plot_height=plot_height,\n",
    "        x_range=x_range, y_range=y_range, outline_line_color=None,\n",
    "        min_border=0, min_border_left=0, min_border_right=0,\n",
    "        min_border_top=0, min_border_bottom=0, **plot_args)\n",
    "    \n",
    "    p.axis.visible = False\n",
    "    p.xgrid.grid_line_color = None\n",
    "    p.ygrid.grid_line_color = None\n",
    "    return p\n",
    "    \n",
    "options = dict(line_color=None, fill_color='#800080', size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And good to go for mapping!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NOTE: `show` turned off to be able to compile the website,\n",
    "#       comment out the last line of this cell for rendering.\n",
    "p = base_plot()\n",
    "#p.add_tile(STAMEN_TERRAIN)\n",
    "p.circle(x=x_wb, y=y_wb, **options)\n",
    "show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernel Density Estimation\n",
    "\n",
    "A common alternative when the number of points grows is to replace plotting every single point by estimating the continuous observed probability distribution. In this case, we will not be visualizing the points themselves, but an abstracted surface that models the probability of point density over space. The most commonly used method to do this is the so called kernel density estimate (KDE). The idea behind KDEs is to count the number of points in a continious way. Instead of using discrete counting, where you include a point in the count if it is inside a certain boundary and ignore it otherwise, KDEs use functions (kernels) that include points but give different weights to each one depending of how far of the location where we are counting the point is.\n",
    "\n",
    "Creating a KDE is very straightfoward in Python. In its simplest form, we can run the following single line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sns.kdeplot(lst['longitude'], lst['latitude'], shade=True, cmap='viridis');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, if we want to include additional layers of data to provide context, we can do so in the same way we would layer up different elements in `matplotlib`. Let us load first the Zip codes in Austin, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zc = gpd.read_file('data/Zipcodes.geojson')\n",
    "zc.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, to overlay both layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, figsize=(9, 9))\n",
    "\n",
    "zc.plot(color='white', linewidth=0.1, ax=ax)\n",
    "\n",
    "sns.kdeplot(lst['longitude'], lst['latitude'], \\\n",
    "            shade=True, cmap='Purples', \\\n",
    "            ax=ax);\n",
    "\n",
    "ax.set_axis_off()\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "## `bokeh` alternative\n",
    "\n",
    "pts.head()\n",
    "\n",
    "from sklearn.neighbors import KernelDensity\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# Setup kernel\n",
    "kde = KernelDensity(metric='euclidean',\n",
    "                    kernel='gaussian', algorithm='ball_tree')\n",
    "# Bandwidth selection\n",
    "gs = GridSearchCV(kde, \\\n",
    "                {'bandwidth': np.linspace(0.1, 1.0, 30)}, \\\n",
    "                cv=3)\n",
    "%time cv = gs.fit(pts[['x', 'y']].values)\n",
    "bw = cv.best_params_['bandwidth']\n",
    "kde.bandwidth = bw\n",
    "# Fit the KDE\n",
    "kde.fit(pts[['x', 'y']].values)\n",
    "\n",
    "# Build a mesh\n",
    "minX, minY = pts[['x', 'y']].values.min(axis=0)\n",
    "maxX, maxY = pts[['x', 'y']].values.max(axis=0)\n",
    "bbox = [minX, minY, maxX, maxY]\n",
    "mn = 100\n",
    "mx = np.linspace(minX, maxX, mn)\n",
    "my = np.linspace(minY, maxY, mn)\n",
    "mxx, myy = np.meshgrid(mx, my)\n",
    "mxxyy = np.hstack((mxx.reshape(-1, 1), myy.reshape(-1, 1)))\n",
    "# Fit to the KDE\n",
    "d = kde.score_samples(mxxyy).reshape(mn, mn)\n",
    "\n",
    "print pts.min()['x'], pts.min()['y']\n",
    "\n",
    "print pts.max()['x'], pts.max()['y']\n",
    "\n",
    "mxxyy.max(axis=0)\n",
    "\n",
    "from bokeh.plotting import figure, show\n",
    "\n",
    "p = base_plot()\n",
    "p.add_tile(STAMEN_TERRAIN)\n",
    "\n",
    "p.image(image=[d], x=minX, y=minY, dw=maxX-minX, dh=maxY-minY, \\\n",
    "        alpha=0.001, palette=\"Blues9\")\n",
    "\n",
    "show(p)\n",
    "-->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('traillop')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "31733d31b68f2bf33a40ef3744aa6e6dabc719cffbfa95fe2fcbd4a0d9e78042"
   }
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
